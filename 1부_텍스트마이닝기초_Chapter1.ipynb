{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1. 텍스트 마이닝 기초\n",
    "* [github 주소](https://github.com/wikibook/textmining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 파일 다운로드 방법1: 저장소를 복제 \n",
    "# !git clone https://github.com/wikibook/textmining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. 텍스트 마이닝의 정의\n",
    "* 텍스트에서 고품질 정보를 추출하는 과정(the process of deriving high-quality information from text)\n",
    "* 텍스트 마이닝 : \n",
    "    * 자연어 처리 기법을 이용해 텍스트를 정형화된 데이터로 변환하고\n",
    "        * 이때 **정형화된 데이터** 는 일정한 길이의 벡터를 의미함 \n",
    "        * 이와 같이 주어진 텍스트를 일정한 길이의 벡터로 변환하는 것을 임베딩이라고 한다 \n",
    "    * 머신러닝 기법을 적용해 우리가 관심이 있는 어떤 사건을 예측하고자 하는 방법론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. 텍스트 마이닝 패러다임의 변화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "# 1.2.1 카운트 기반의 문서 표현\n",
    "#----------------------------------------\n",
    "# 문장에 있는 단어들의 개수를 세고, 주로 사용된 단어들을 이용해 그 문장의 내용을 파악하는 것 \n",
    "# 카운트 기반의 문서 표현은 이러한 아이디어를 바탕으로, 문서를 사용된 단어들의 빈도로 표현하는 것이다 \n",
    "# 문서의 일정 길이를 벡토로 변환한다고 했을 때, 카운트 기반의 문서 표현은 각 단어별로 개수를 세어서 \n",
    "# 이를 벡터로 만든다고 이해하면 쉽다 \n",
    "\n",
    "# 단점: \n",
    "    # 이 과정에서 단어들이 텍스트에 나타난 **순서에 대한 정보는** 사라진다 \n",
    "    # 문맥에 대한 정보 사라짐\n",
    "      \n",
    "# 장점: \n",
    "    # 대신, 단어에 대한 통계만이 남게 된다 \n",
    "    # 텍스트 내용을 기반으로 어떤 사건을 예측하는 것은 이 정도의 정보만으로 꽤 훌륭한 결과를 보일 수 있다  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "# 1.2.2 시퀀스 기반의 문서 표현\n",
    "#----------------------------------------\n",
    "# 각 단어를 먼저 벡터로 변환하고, 이러한 벡터의 연속된 나열 혹은 시퀀스로 문서를 표현한다\n",
    "\n",
    "# 단점: \n",
    "    # 원핫 인코딩: 단어의 개수가 커지면, 벡터로 변환한 크기가 지나치게 커짐 \n",
    "        # 딥러닝 기법에서는 특별한 과정을 거쳐: 짧은 벡터로 변환하는 임베딩을 거침 \n",
    "        # 문서는 가변의 단어로 구성되므로, 문서를 임베딩할 경우 단어 벡터의 시퀀스로 표현할 경우 길이가 제각각\n",
    "            # 머신러닝/딥러닝 가변길이의 입력을 허용하지 않음 \n",
    "            # 일정한 길이로 맞추는 작업이 필요함 \n",
    "            # 문서의 단어 수가 미리 정한 값 이상이면 앞뒤의 단어를 잘라 길이를 맞춤\n",
    "            # 단어 수가 모자랄 때는 공백이나 미리 약속한 의미 없는 값으로 모자란 부분을 메꿈(padding)\n",
    "            # **문서를 일정한 길이의 벡터로 변환** 가능 \n",
    "      \n",
    "# 장점: \n",
    "    # 문맥을 이해함으로써 더 정확하게 문장의 의미를 이해할 수 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 용어 정리 \n",
    "# 텍스트, 문서, 문장 \n",
    "# 텍스트 \n",
    "    # 분석의 대상이 되는 문자열 \n",
    "# 문서\n",
    "    # 하나의 일관된 목적 혹은 주제를 갖고 쓰여진 길로 정의함      \n",
    "# 문장\n",
    "    # 생각이나 감정을 말로 표현할 때 완결된 내용을 나타내는 최소 단위 \n",
    "# 말뭉치(corpus)\n",
    "    # 언어 연구를 위해 컴퓨터가 텍스트를 가공,처리,분석할 수 있는 형태로 모아 놓은 자료의 집합 \n",
    "    # 자연언어 연구를 위해 특정한 목적을 가지고 언어의 표본을 추출한 집합 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. 텍스트 마이닝에 필요한 지식과 도구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "# 1.3.1 자연어 처리 기법\n",
    "#----------------------------------------\n",
    "# 자연어 처리\n",
    "    # 컴퓨터를 이용해 사람의 자연어를 분석하고 처리하는 기술\n",
    "    # 형태소 분석, 품사 부착(POS), 구절 단위 분석, 구문 분석 등 \n",
    "    # 텍스트를 전처리해 다양한 분석을 할 수 있는 형태로 변환하는데 적용됨 \n",
    "    # 텍스트를 일정한 길이의 벡터로 변환하기 위해 쓰이는 기법 \n",
    "\n",
    "# 텍스트 전처리를 위한 기법 \n",
    "    # 라이브러리 : NLTK(Natural Language Tool-kit), KoNLPY, + kiwi\n",
    "    # 토큰화(tokenize)\n",
    "    # 정규회(Normalization)\n",
    "        # 어간 추출(stemming)\n",
    "        # 표제어 추출(lemmatize)\n",
    "    # 품사 태깅(POS - tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "# 1.3.2 통계학과 선형대수\n",
    "#----------------------------------------\n",
    "# 대용량 데이터 : 행렬 이해 // 벡터 변환 및 이해 : 선형 대수 이해 필요 \n",
    "# 패키지 : numpy, pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "# 1.3.3 시각화 기법\n",
    "#----------------------------------------\n",
    "# 막대 그래프, 워드클라우드 기법 많이 사용됨 \n",
    "# 토픽 모델링 : 각 토픽의 비중 등을 쉽게 나타내려고 시각화 기법을 많이 활용\n",
    "# 패키지 : matplotlib, seaborn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "# 1.3.4 머신러닝\n",
    "#----------------------------------------\n",
    "# 패키지 : 사이킷런(Scikit-learn)\n",
    "# 기계학습\n",
    "    # 지도 학습(Supervised Learning)\n",
    "        # 회귀, 분류 \n",
    "    # 비지도 학습(Unsupervised Learning)\n",
    "        # 클러스터링, 차원 축소 \n",
    "    # 강화 학습(Reinforcement Learning)\n",
    "# 텍스트 마이닝 \n",
    "    # 주로 지도학습의 분류 방법이 많이 사용됨\n",
    "    # 상황에 따라 클러스터링, 차원 축소 방법 사용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "# 1.3.5 딥러닝\n",
    "#----------------------------------------\n",
    "# 패키지 : 케라스(Keras), 파이토치(PyTorch)\n",
    "# 딥러닝: \n",
    "    # 머신러닝의 한 분류에 속하는 인공신경망에서 은닉층에 깊게(deep) 쌓은 신경망 구조를 활용해 학습하는 알고리즘 \n",
    "# 초기 : RNN, LSTM, CNN 등\n",
    "# 현재 : Transformer 기반 BERT, GPT\n",
    "# 전이학습 \n",
    "    # BERT, GPT는 전이학습/트랜스퍼 러닝 \n",
    "    # 이미 학습된 모형을 이용하므로 학습의 부담도 크게 줄어듦 \n",
    "    # 기본적, 학습이 된 모형에 대해 나의 데이터를 이용해 미세조정학습을 수행\n",
    "    # 전체 학습에 비해 미세조정학습은 자원의 소모(시간,컴퓨팅 파워)가 훨씬 덜하다 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. 텍스트 마이닝의 주요 적용 분야"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "# 1.4.1 문서 분류\n",
    "#----------------------------------------\n",
    "# 주어진 문서에 대해 미리 정의된 클래스로 분류하는 작업을 말함 \n",
    "# ex1. 뉴스 분야 분류  \n",
    "    # 뉴스 기사를 읽고 정치, 경제, 연예, 스포츠 부류 \n",
    "# ex2. 스팸 분류 \n",
    "    # 스팸 메일 여부 결정 \n",
    "# ex3. 감성 분류 \n",
    "    # 문서의 내용 호의적, 비호의적인지 알아내는 분류 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "# 1.4.2 문서 생성(Text Generation)\n",
    "#----------------------------------------\n",
    "# 사람이 쓴 것과 유사한 문장을 만들어내는 작업 \n",
    "# ex1. 시(문학) 생성, 농담 생성, 이야기 생성 등  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "# 1.4.3 문서 요약\n",
    "#----------------------------------------\n",
    "# 주어진 문서에서 중요하고 흥미 있는 내용을 추출해 요약문을 생성하는 작업 \n",
    "# ex1. sequence-to-sequence\n",
    "    # 단어의 시퀀스를 입력 받아 다시 단어의 시퀀스를 출력하는 문제 \n",
    "    # 훨씬 짧지만 다시 시퀀스의 형태로 출력함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "# 1.4.4 질의응답 (Question Answering)\n",
    "#----------------------------------------\n",
    "# 주어진 문장(context)를 읽고, 주어진 문제(question)에 대한 올바른 답(answer)를 생성하는 작업 \n",
    "# 공학적: 문서 요약과 유사함 \n",
    "# ex1. sequence-to-sequence\n",
    "    # 챗봇의 주요 미래 기술"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "# 1.4.5 기계번역 (Machine Translation)\n",
    "#----------------------------------------\n",
    "# 한 언어로 작성된 문서를 다른 언어로 번역하는 것 \n",
    "# 두 가지 언어체계를 완벽하게 이해해야 하므로 '자연어 이해(natural language understanding)'을 전제로 함 \n",
    "# ex1. sequence-to-sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "# 1.4.6 토픽 모델링\n",
    "#----------------------------------------\n",
    "# 여러 문서에서 공통으로 등장하는 토픽(주제)를 추출하는 방법\n",
    "# 다수의 문서에 잠재된 내용을 파악하는데 활용함 \n",
    "# ex1. 연설문 분석\n",
    "    # 다양한 토픽 파악\n",
    "    # 각 토픽이 한 문서에서 어느 정도의 비중을 차지하는지 정보 분석 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. 이 책의 실습 환경과 사용 소프트웨어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "# 1.5.1 기본 실습 환경\n",
    "#----------------------------------------\n",
    "# 기본 환경 : Windows 10 (64bit), python 3.8 (anaconda)\n",
    "# NLTK(자연어 처리 라이브러리)\n",
    "# scikit-learn(머신러닝)\n",
    "# numpy, pandas (데이터 처리 및 시각화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "# 1.5.2 자연어 처리 관련 라이브러리\n",
    "#----------------------------------------\n",
    "# NLTK(영문 자연어 처리)\n",
    "# KoNLPy(한글 자연어 처리)\n",
    "# TextBlob, AFINN, VADER(감성분석)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "# 1.5.3 머신러닝 관련 라이브러리\n",
    "#----------------------------------------\n",
    "# scikit-learn(텍스트 마이닝 패키지)\n",
    "# Gensim(토픽 모델링)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "# 1.5.4 딥러닝 관련 라이브러리 \n",
    "#----------------------------------------\n",
    "# 텐서플로(Tensorflow- 10장 RNN, 12장 CNN)\n",
    "# 파이토치(Pytorch - 14~16장 BERT 구현)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83241ebad412f60d5ea127abea65ca420ff500f141f82c4523b10d4feff16ff2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
